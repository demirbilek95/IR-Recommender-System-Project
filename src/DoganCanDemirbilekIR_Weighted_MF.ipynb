{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reproducability\n",
    "np.random.seed(seed = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "movies = pd.read_csv(\"data/movies.csv\") # we'll use this dataframe also later to retrieve title and genres\n",
    "ratings = pd.read_csv(\"data/ratings.csv\")\n",
    "\n",
    "print(\"Columns of movies dataset: \",movies.columns)\n",
    "print(\"Columns of ratings dataset: \",ratings.columns)\n",
    "\n",
    "print(\"\\nNumber of movies in dataset: \", len(movies.movieId.unique()))\n",
    "print(\"Number of users in dataset: \", len(ratings.userId.unique()))\n",
    "\n",
    "# we merge two dataframe to have all the movies including the ones which are not voted\n",
    "df = pd.merge(ratings, movies, on = \"movieId\", how=\"right\")\n",
    "\n",
    "# to obtain the desired matrix form we use pandas.pivot_table function\n",
    "# users are on the rows, movies are on the columns\n",
    "\n",
    "C = df.pivot_table(index = \"userId\", columns = \"movieId\", values = \"rating\", dropna=False)\n",
    "\n",
    "# just to have correct datatype (it is changed because of NA values)\n",
    "C.index = C.index.astype(int)\n",
    "\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each user has at least 20, at max 2698 ratings among the 9742 movies\n",
    "print(\"The least voted user has voted {} times\".format(C.notnull().sum(axis=1).min()))\n",
    "print(\"The most voted user has voted {} times\".format(C.notnull().sum(axis=1).max()))\n",
    "\n",
    "# some movies never rated, at most they rated 329 times by different users\n",
    "print(\"The least rated movie has voted {} times\".format(C.notnull().sum(axis=0).min()))\n",
    "print(\"The most rated movie has voted {} times\".format(C.notnull().sum(axis=0).max()))\n",
    "\n",
    "# minimum and maximum rating\n",
    "print(\"Minimum rating:\",C.min(axis=0).min())\n",
    "print(\"Maximum rating:\",C.max(axis=0).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all unobserved values will be filled with 0 for the sake of cost function\n",
    "C.fillna(0,inplace=True)\n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted Alternating Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_user, num_item = C.shape\n",
    "num_factor = 50 # I decided number of features, this number will be decided by using CV later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\sum_{i,j \\in Obs}{w_{i,j}(C_{i,j} - U_{i,j} V_{i,j}^T)^2} + \\lambda {(\\lVert U \\rVert^2 + \\lVert V \\rVert^2)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(C, U, V, reg, w):\n",
    "    C_prime = np.dot(U, V.T)\n",
    "    return w * np.sum((C.values - C_prime) ** 2) + reg * (np.linalg.norm(U) ** 2 + np.linalg.norm(V) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To optimize the cost function, we start by setting one of the vectors as constant. For this example we can use item vector $V$. Then we can take the derivate of the loss function with respect to other vector. For the sake of simplicity $i,j$ won't be showed in the notation\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial U} = -2 \\sum{w(C - U V^T) V} + 2 \\lambda U = 0 \\\\\n",
    "= - w (C - U V^T) V + \\lambda U = 0 \\\\\n",
    "= U(w V^T V + \\lambda I) = w C V \\\\\n",
    "= U = w C V (w V^T V + \\lambda I)^{-1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can calculate the $V$ by following same procedure.\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial V} = V = w C U (w U^T U + \\lambda I)^{-1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the analytical solution, please note that instead of lambda \n",
    "# we used reg as a parameter since lambda exist in python as keyword\n",
    "\n",
    "def recompute_factors(ratings, fixed_vecs, solve_vecs, num_factor, reg , w):\n",
    "    \n",
    "    A = w * fixed_vecs.T.dot(fixed_vecs) + np.eye(num_factor) * reg\n",
    "    b = w * ratings.dot(fixed_vecs)\n",
    "    A_inv = np.linalg.inv(A)\n",
    "    solve_vecs = b.dot(A_inv)\n",
    "    return solve_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WALS(C, num_factor, num_user, num_item, reg, num_iter, verbose = False):\n",
    "    \n",
    "    cost_list = []                                  # cost_list is for storing cost for each iteration\n",
    "    # randomly initialize the matrices U and V\n",
    "    U = np.random.rand(num_user, num_factor)\n",
    "    V = np.random.rand(num_item, num_factor)\n",
    "    \n",
    "    if verbose == True:\n",
    "        print(\"Iteration \\t\\t Cost\")\n",
    "        \n",
    "    for i in range(1,num_iter+1): # range(1,num_iter +1) to start the iteration from 1 not 0\n",
    "        \n",
    "        # fix U and find V , reg and w are chosen by arbitrary (w has no effect on the observations)\n",
    "        V = recompute_factors(C.T.values, U, V, num_factor, reg , 1)\n",
    "        # fix V and find U\n",
    "        U = recompute_factors(C.values, V, U, num_factor, reg, 1)\n",
    "        \n",
    "        cost = cost_function(C, U, V, reg, 1)\n",
    "        \n",
    "        if verbose == True:\n",
    "            print(i,\"\\t\\t\",cost)\n",
    "            \n",
    "        cost_list.append(cost)\n",
    "    \n",
    "    # return dataframe which is similar to C\n",
    "    C_prime = pd.DataFrame(np.dot(U, V.T), columns = C.columns, index = C.index)\n",
    "        \n",
    "    return C_prime, cost_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "C_prime, cost_list = WALS(C, num_factor, num_user, num_item, 0.5, 100, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,8))\n",
    "plt.title(\"Change in Cost with Iterations\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.plot(cost_list);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(C, C_prime, user_id, num_recommendation):\n",
    "    mask = np.where(C == 0)                        # filtering the movies which is not watched\n",
    "    user = user_id - 1                        # in numpy, indexing starts with 0, in dataframe it is 1\n",
    "\n",
    "    user_column = mask[1][mask[0] == user]    # to filter movies (were in columns) in C_prime\n",
    "    \n",
    "    scores = C_prime.iloc[user,user_column]\n",
    "    scores_reduced = scores.sort_values(ascending = False)[:num_recommendation]   # sort the scores descending order\n",
    "    \n",
    "    df = pd.DataFrame(scores_reduced)\n",
    "    df.reset_index(inplace=True)                                 # to get movieId as column\n",
    "    df.columns = [\"movieId\", \"Score\"]\n",
    "    df = pd.merge(df,movies,on=\"movieId\")                        # to get also title and genres\n",
    "    \n",
    "    print(\"Movie Recommendations for user {}\".format(user_id))\n",
    "\n",
    "    return df            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend(C, C_prime, 455, num_recommendation=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deciding Parameters with CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to use it in cross validation\n",
    "def calculate_test_error(array1, array2):\n",
    "    return np.sum(np.square(array1 - array2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_CV(C, param_list, fold, latent_factor = True):\n",
    "    # mask the observations\n",
    "    mask = np.nonzero(C.values)\n",
    "    idx = len(C.values[mask]) // fold  # will be used for indexing mask, in other words test size\n",
    "    \n",
    "    param_error = {}                # store the results for each param in dictionary\n",
    "    for param in param_list:\n",
    "        print(\"Evaluating parameter {}\".format(param))\n",
    "\n",
    "        cost = []\n",
    "        for i in range(fold): \n",
    "\n",
    "            C_train = C.copy()              \n",
    "            test_mask_row = mask[0][i*idx : (i+1)*idx]   # preparing test set\n",
    "            test_mask_column = mask[1][i*idx : (i+1)*idx]\n",
    "\n",
    "            # keep those values in a seperated array\n",
    "            test_array = C_train.values[test_mask_row, test_mask_column]\n",
    "\n",
    "            # set those values to 0, like we didn't observe them at all\n",
    "            C_train.iloc[test_mask_row, test_mask_column] = 0.0\n",
    "            \n",
    "            # this if statement is just for using the function for latent_factor and reg\n",
    "            if latent_factor == True:\n",
    "                # now calculate the C_prime, 30 iteration is enough to converge and save time from execution\n",
    "                C_prime, cost_list = WALS(C_train, param, C.shape[0], C.shape[1], 0.5, 30)\n",
    "            else:\n",
    "                C_prime, cost_list = WALS(C_train, 50, C.shape[0], C.shape[1], param, 30)\n",
    "\n",
    "            # get the approximated results for test dataset\n",
    "            predicted_array = C_prime.values[test_mask_row, test_mask_column]\n",
    "\n",
    "            # calculate the test error and store it\n",
    "            test_error = calculate_test_error(test_array, predicted_array)\n",
    "            cost.append(test_error)\n",
    "              \n",
    "        param_error[param] = cost\n",
    "        \n",
    "    return param_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# this part may take time since there is fold * len(param_list) operation\n",
    "\n",
    "num_latent_list = np.linspace(10,100,10, dtype=np.int)\n",
    "\n",
    "latent_factor_CV_error = param_CV(C, num_latent_list, 5)\n",
    "# construct a dataframe from errors\n",
    "latent_factors_error_df = pd.DataFrame(latent_factor_CV_error, dtype=np.float)\n",
    "\n",
    "# first take the mean of dataframe columns-wise and sort \n",
    "# it according to index to find the minimum among the columns\n",
    "\n",
    "idx = np.argsort(latent_factors_error_df.mean(axis=0).values)\n",
    "latent_factors_ordered = latent_factors_error_df.columns[idx]\n",
    "print(\"Best number of latent factor is {}\".format(latent_factors_ordered[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularizaiton $\\lambda$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# same process for regularization parameter to get the one which has the smallest error mean\n",
    "\n",
    "reg_list = np.linspace(0.1,1,10, dtype=np.float)\n",
    "\n",
    "reg_CV_error = param_CV(C, reg_list, 5 ,latent_factor = False)\n",
    "reg_error_df = pd.DataFrame(reg_CV_error, dtype=np.float)\n",
    "\n",
    "idx = np.argsort(reg_error_df.mean(axis=0).values)\n",
    "reg_ordered = reg_error_df.columns[idx]\n",
    "print(\"Best number of regularization parameter is {}\".format(reg_ordered[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cold Start Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_with_cold_start(C, C_prime, user_id, num_recommendation):\n",
    "    # check that user has no rating before, if yes return the most popular movies\n",
    "    # simply by taking the mean of the movies\n",
    "    \n",
    "    user_votes = C.loc[user_id, :].unique()\n",
    "    \n",
    "    if len(user_votes) == 1 and user_votes[0] == 0:\n",
    "        popular_movies = C.mean(axis=0).sort_values()[::-1][:num_recommendation]\n",
    "        df = pd.DataFrame(popular_movies)\n",
    "        df.reset_index(inplace=True)                                 # to get movieId as column\n",
    "        df.columns = [\"movieId\", \"Score\"]\n",
    "        df = pd.merge(df,movies,on=\"movieId\")                        # to get also title and genres\n",
    "        print(\"Movie Recommendations for user {}\".format(user_id))\n",
    "        return df\n",
    "    else:\n",
    "        # call normal recommend function\n",
    "        recommend(C, C_prime, user_id, num_recommendation)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new user to system which has no ratings\n",
    "C.loc[611,:] = np.zeros(len(C.columns))\n",
    "\n",
    "# constructing C_prime with new C by using parameters that we found, actually make no difference\n",
    "# for new users since we recommend them the most popular ones\n",
    "C_prime, cost_list = WALS(C, 40, C.shape[0], C.shape[1], 0.3, 100)\n",
    "\n",
    "recommend_with_cold_start(C, C_prime, 611,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://files.grouplens.org/datasets/movielens/ml-latest.zip\n",
    "\n",
    "https://datajobs.com/data-science-repo/Recommender-Systems-[Netflix].pdf\n",
    "\n",
    "https://developers.google.com/machine-learning/recommendation/collaborative/matrix\n",
    "\n",
    "http://ethen8181.github.io/machine-learning/recsys/1_ALSWR.html\n",
    "\n",
    "https://www.ethanrosenthal.com/2016/01/09/explicit-matrix-factorization-sgd-als/"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Sahibinden Veri Cekme Full.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
